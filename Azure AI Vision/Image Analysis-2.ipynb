{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "import requests\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global cv_client\n",
    "\n",
    "    try:\n",
    "        ai_endpoint = ''\n",
    "        ai_key = ''\n",
    "\n",
    "        # Get image\n",
    "        image_url = 'https://www.newsnationnow.com/wp-content/uploads/sites/108/2024/05/664cbf44098e65.46285470.jpeg?w=2560&h=1440&crop=1'\n",
    "        '''\n",
    "        if len(sys.argv) > 1:\n",
    "            image_file = sys.argv[1]\n",
    "\n",
    "        with open(image_file, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "        '''\n",
    "\n",
    "        # Authenticate Azure AI Vision client\n",
    "        cv_client = ImageAnalysisClient(\n",
    "            endpoint=ai_endpoint,\n",
    "            credential=AzureKeyCredential(ai_key)\n",
    "        )\n",
    "        \n",
    "        # Analyze image\n",
    "        AnalyzeImage(image_file, image_data, cv_client)\n",
    "        \n",
    "        # Background removal\n",
    "        BackgroundForeground(ai_endpoint, ai_key, image_file)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalyzeImage(image_filename, image_data, cv_client):\n",
    "    print('\\nAnalyzing image...')\n",
    "\n",
    "    try:\n",
    "        # Get result with specified features to be retrieved\n",
    "        result = cv_client.analyze_from_url(\n",
    "            \n",
    "            visual_features=[\n",
    "                VisualFeatures.CAPTION,\n",
    "                VisualFeatures.DENSE_CAPTIONS,\n",
    "                VisualFeatures.TAGS,\n",
    "                VisualFeatures.OBJECTS,\n",
    "                VisualFeatures.PEOPLE],\n",
    "        )\n",
    "        \n",
    "\n",
    "    except HttpResponseError as e:\n",
    "        print(f\"Status code: {e.status_code}\")\n",
    "        print(f\"Reason: {e.reason}\")\n",
    "        print(f\"Message: {e.error.message}\")\n",
    "\n",
    "# Display analysis results\n",
    "# Get image captions\n",
    "if result.caption is not None:\n",
    "    print(\"\\nCaption:\")\n",
    "    print(\" Caption: '{}' (confidence: {:.2f}%)\".format(result.caption.text, result.caption.confidence * 100))\n",
    "\n",
    "# Get image dense captions\n",
    "if result.dense_captions is not None:\n",
    "    print(\"\\nDense Captions:\")\n",
    "    for caption in result.dense_captions.list:\n",
    "        print(\" Caption: '{}' (confidence: {:.2f}%)\".format(caption.text, caption.confidence * 100))\n",
    "\n",
    "# Get image tags\n",
    "if result.tags is not None:\n",
    "    print(\"\\nTags:\")\n",
    "    for tag in result.tags.list:\n",
    "        print(\" Tag: '{}' (confidence: {:.2f}%)\".format(tag.name, tag.confidence * 100))\n",
    "\n",
    "# Get objects in the image\n",
    "if result.objects is not None:\n",
    "    print(\"\\nObjects in image:\")\n",
    "\n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_filename)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'cyan'\n",
    "\n",
    "    for detected_object in result.objects.list:\n",
    "        # Print object name\n",
    "        print(\" {} (confidence: {:.2f}%)\".format(detected_object.tags[0].name, detected_object.tags[0].confidence * 100))\n",
    "\n",
    "        # Draw object bounding box\n",
    "        r = detected_object.bounding_box\n",
    "        bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height)) \n",
    "        draw.rectangle(bounding_box, outline=color, width=3)\n",
    "        plt.annotate(detected_object.tags[0].name,(r.x, r.y), backgroundcolor=color)\n",
    "\n",
    "    # Save annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    outputfile = 'objects.jpg'\n",
    "    fig.savefig(outputfile)\n",
    "    print('  Results saved in', outputfile)\n",
    "\n",
    "# Get people in the image\n",
    "# Get people in the image\n",
    "if result.people is not None:\n",
    "    print(\"\\nPeople in image:\")\n",
    "\n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_filename)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'cyan'\n",
    "\n",
    "    for detected_people in result.people.list:\n",
    "        # Draw object bounding box\n",
    "        r = detected_people.bounding_box\n",
    "        bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height))\n",
    "        draw.rectangle(bounding_box, outline=color, width=3)\n",
    "\n",
    "        # Return the confidence of the person detected\n",
    "        #print(\" {} (confidence: {:.2f}%)\".format(detected_people.bounding_box, detected_people.confidence * 100))\n",
    "\n",
    "    # Save annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    outputfile = 'people.jpg'\n",
    "    fig.savefig(outputfile)\n",
    "    print('  Results saved in', outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackgroundForeground(endpoint, key, image_file):\n",
    "    # Define the API version and mode\n",
    "    api_version = \"2023-02-01-preview\"\n",
    "    mode=\"backgroundRemoval\" # Can be \"foregroundMatting\" or \"backgroundRemoval\"\n",
    "    \n",
    "    # Remove the background from the image or generate a foreground matte\n",
    "    print('\\nRemoving background from image...')\n",
    "\n",
    "    url = \"{}computervision/imageanalysis:segment?api-version={}&mode={}\".format(endpoint, api_version, mode)\n",
    "\n",
    "    headers= {\n",
    "        \"Ocp-Apim-Subscription-Key\": key, \n",
    "        \"Content-Type\": \"application/json\" \n",
    "    }\n",
    "\n",
    "    image_url=\"https://github.com/MicrosoftLearning/mslearn-ai-vision/blob/main/Labfiles/01-analyze-images/Python/image-analysis/{}?raw=true\".format(image_file)  \n",
    "\n",
    "    body = {\n",
    "        \"url\": image_url,\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=body)\n",
    "\n",
    "    image=response.content\n",
    "    with open(\"backgroundForeground.png\", \"wb\") as file:\n",
    "        file.write(image)\n",
    "    print('  Results saved in backgroundForeground.png \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
