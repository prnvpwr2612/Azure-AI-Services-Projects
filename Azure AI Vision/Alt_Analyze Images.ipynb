{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import namespaces\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Azure AI Vision client\n",
    "cv_client = ImageAnalysisClient(\n",
    "    endpoint=ai_endpoint,\n",
    "    credential=AzureKeyCredential(ai_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get result with specified features to be retrieved\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[\n",
    "        VisualFeatures.CAPTION,\n",
    "        VisualFeatures.DENSE_CAPTIONS,\n",
    "        VisualFeatures.TAGS,\n",
    "        VisualFeatures.OBJECTS,\n",
    "        VisualFeatures.PEOPLE],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display analysis results\n",
    "# Get image captions\n",
    "if result.caption is not None:\n",
    "    print(\"\\nCaption:\")\n",
    "    print(\" Caption: '{}' (confidence: {:.2f}%)\".format(result.caption.text, result.caption.confidence * 100))\n",
    "\n",
    "# Get image dense captions\n",
    "if result.dense_captions is not None:\n",
    "    print(\"\\nDense Captions:\")\n",
    "    for caption in result.dense_captions.list:\n",
    "        print(\" Caption: '{}' (confidence: {:.2f}%)\".format(caption.text, caption.confidence * 100))\n",
    "\n",
    "# Get image tags\n",
    "if result.tags is not None:\n",
    "    print(\"\\nTags:\")\n",
    "    for tag in result.tags.list:\n",
    "        print(\" Tag: '{}' (confidence: {:.2f}%)\".format(tag.name, tag.confidence * 100))\n",
    "\n",
    "# Get objects in the image\n",
    "if result.objects is not None:\n",
    "    print(\"\\nObjects in image:\")\n",
    "\n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_filename)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'cyan'\n",
    "\n",
    "    for detected_object in result.objects.list:\n",
    "        # Print object name\n",
    "        print(\" {} (confidence: {:.2f}%)\".format(detected_object.tags[0].name, detected_object.tags[0].confidence * 100))\n",
    "\n",
    "        # Draw object bounding box\n",
    "        r = detected_object.bounding_box\n",
    "        bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height)) \n",
    "        draw.rectangle(bounding_box, outline=color, width=3)\n",
    "        plt.annotate(detected_object.tags[0].name,(r.x, r.y), backgroundcolor=color)\n",
    "\n",
    "    # Save annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    outputfile = 'objects.jpg'\n",
    "    fig.savefig(outputfile)\n",
    "    print('  Results saved in', outputfile)\n",
    "\n",
    "# Get people in the image\n",
    "# Get people in the image\n",
    "if result.people is not None:\n",
    "    print(\"\\nPeople in image:\")\n",
    "\n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_filename)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'cyan'\n",
    "\n",
    "    for detected_people in result.people.list:\n",
    "        # Draw object bounding box\n",
    "        r = detected_people.bounding_box\n",
    "        bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height))\n",
    "        draw.rectangle(bounding_box, outline=color, width=3)\n",
    "\n",
    "        # Return the confidence of the person detected\n",
    "        #print(\" {} (confidence: {:.2f}%)\".format(detected_people.bounding_box, detected_people.confidence * 100))\n",
    "\n",
    "    # Save annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    outputfile = 'people.jpg'\n",
    "    fig.savefig(outputfile)\n",
    "    print('  Results saved in', outputfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the background from the image or generate a foreground matte\n",
    "print('\\nRemoving background from image...')\n",
    "\n",
    "url = \"{}computervision/imageanalysis:segment?api-version={}&mode={}\".format(endpoint, api_version, mode)\n",
    "\n",
    "headers= {\n",
    "    \"Ocp-Apim-Subscription-Key\": key, \n",
    "    \"Content-Type\": \"application/json\" \n",
    "}\n",
    "\n",
    "image_url=\"https://github.com/MicrosoftLearning/mslearn-ai-vision/blob/main/Labfiles/01-analyze-images/Python/image-analysis/{}?raw=true\".format(image_file)  \n",
    "\n",
    "body = {\n",
    "    \"url\": image_url,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=body)\n",
    "\n",
    "image=response.content\n",
    "with open(\"backgroundForeground.png\", \"wb\") as file:\n",
    "    file.write(image)\n",
    "print('  Results saved in backgroundForeground.png \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
